{
    "en": {
        "hero_greeting": "Hello World",
        "hero_name": "I am João, ",
        "hero_role_one": "Python Developer ",
        "hero_role_two": "& Data Engineer.",
        "hero_subtitle": "Building packages, pipelines, and insights that drive decisions.",
        "about_one": "A <strong>Python Developer</strong> with solid experience in <strong>Data Engineering</strong> and Business Intelligence, transforming data into strategic insights using tools like <strong>Spark, SQL, and Azure DevOps</strong>. I'm currently focused on building <strong>Python packages, internal libraries, and automation tools</strong> that optimize workflows and enhance productivity across data teams.",
        "about_two": "I’m passionate about building and contributing to solutions that enhance <strong>productivity<strong>, connect people, and enable sustainable <strong>growth</strong>. I’m constantly seeking opportunities to apply my skills in impactful projects and contribute to innovative, purpose-driven teams.",
        "work_vale": "I led the development of a closed-source <strong>Python</strong> library designed to streamline and accelerate the entire the data analysis lifecycle—from exploratory analysis and preprocessing to integration with corporate systems, process automation, advanced analytics, and machine learning modeling. Built to be accessible for non-technical business users, the library enabled intuitive, structured insight generation and helped democratize data across the organization. To ensure quality, scalability, and maintainability, I implemented a robust <strong>CI/CD</strong> pipeline using <strong>Docker</strong> for isolated environments, <strong>SonarQube</strong> for static code analysis, automated testing, and structured version control, establishing a secure and reproducible development process.",
        "work_bb": "I contributed to strategic data initiatives using <strong>Python, Apache Spark</strong>, and <strong>DB2</strong>, applying <strong>descriptive and predictive modeling</strong> to identify customer and product churn risks—resulting in an <strong>81%</strong> reduction in churn. I also supported ESG analysis projects, delivering insights aligned with sustainable investment guidelines, and led the development of executive dashboards for C-level monitoring. Additionally, I built Airflow-orchestrated pipelines to monitor BI tools like <strong>Power BI, Spotfire, Cognos, OBIEE</strong>, and <strong>SAS</strong>, ensuring system reliability. My work also included designing analytics solutions to assess employee proficiency, integrating structured data and dashboards to support HR strategies and organizational growth.",
        "work_sefaz": "I worked on the development of <strong>decision support systems</strong> for monitoring corporate tax compliance and vehicle tax control. I contributed to improving platforms for tracking payment declarations and controlling agricultural producers’ tax data. My responsibilities included <strong>PL/SQL development, data integration</strong> using <strong>SAS (DI, Flow, Viya, Guide)</strong>, <strong>SQL</strong> and <strong>Python</strong>, as well as data modeling with PowerDesigner and version control with <strong>Git</strong>. I orchestrated ETL pipelines, built dashboards and reports, and supported data ingestion into <strong>Data Warehouses, Data Marts</strong>, and operational databases. Additionally, I facilitated communication between Product Owners and development teams, ensuring agile delivery through Scrum/Kanban practices.",
        "work_cda": "I supported the <strong>migration of the ERP system and database to Oracle 12c</strong>, adapting and developing <strong>PL/SQL routines</strong> and building <strong>modular interfaces using Java</strong>. I worked on data modeling, transformation, and ETL processes, and created <strong>reports and dashboards</strong> for commercial managers and internal auditors. Additionally, I developed <strong>scoring models</strong> to optimize business areas and provided <strong>user support and issue resolution</strong> to ensure system reliability.",
        "contact_title": "Get In Touch",
        "contact_text": "Let’s connect and explore how I can bring value to your next data challenge!"
    },
    "pt": {
        "hero_greeting": "Olá Mundo",
        "hero_name": "Sou o João, ",
        "hero_role_one": "Dev Python ",
        "hero_role_two": "& Eng. de Dados.",
        "hero_subtitle": "Criando pacotes, pipelines e insights que impulsionam decisões.",
        "about_one": "Um <strong>Desenvolvedor Python</strong> com sólida experiência em <strong>Engenharia de Dados</strong> e Business Intelligence, transformando dados em insights estratégicos a partir de ferramentas como <strong>Spark, SQL e Azure DevOps</strong>. Atualmente, estou focado na criação de <strong>pacotes Python, bibliotecas internas e ferramentas de automação</strong> que optimizam os fluxos de trabalho e aumentam a produtividade das equipes de dados.",
        "about_two": "Sou fascinado por criar e contribuir para soluções que aumentem a <strong>produtividade</strong>, conectem pessoas e permitam um <strong>crescimento</strong> sustentável. Estou constantemente à procura de oportunidades para aplicar as minhas competências em projectos de impacto e contribuir para equipas inovadoras e orientadas para os <strong>objetivos</strong>.",
        "work_vale": "Liderei o desenvolvimento de uma biblioteca <strong>Python</strong> de código fechado criada para simplificar e acelerar todo o ciclo de vida da análise de dados - desde a análise exploratória e o pré-processamento até à integração com sistemas internos, automação de processos, análise avançada e modelagem de aprendizagem automática. Criada para ser acessível a equipes empresariais não técnicas, a biblioteca permitiu a geração intuitiva de conhecimentos estruturados e ajudou a democratizar os dados em toda a organização. Para garantir qualidade, escalabilidade e manutenção, implementei um robusto <strong>CI/CD</strong> pipeline usando <strong>Docker</strong> para ambientes isolados, <strong>SonarQube</strong> para análise de código estático, testes automatizados e controle de versão estruturado, estabelecendo um processo de desenvolvimento seguro e reproduzível.",
        "work_bb": "Contribuí para iniciativas de dados estratégicos usando <strong>Python, Apache Spark</strong>, e <strong>DB2</strong>, aplicando <strong>modelagem descritiva e preditiva</strong> para identificar riscos de rotatividade de clientes e produtos - resultando em uma redução de <strong>81%</strong> na rotatividade. Também apoiei projectos de análise ASG, fornecendo informações alinhadas com as diretrizes de investimento sustentáveis , e liderei o desenvolvimento de painéis executivos para monitoramento ao nível da direção. Além disso, construí pipelines orquestrados por esteiras de dados para monitorar ferramentas de BI como <strong>Power BI, Spotfire, Cognos, OBIEE</strong> e <strong>SAS</strong>, garantindo a confiabilidade do sistema. O meu trabalho também incluiu a conceção de soluções analíticas para avaliar a proficiência dos funcionários, integrando dados estruturados e dashboards para apoiar estratégias de RH e crescimento organizacional.",
        "work_sefaz": "Trabalhei no desenvolvimento de <strong>sistemas de apoio à decisão</strong> para fiscalizar o cumprimento dos impostos sobre a região e o controle do imposto sobre veículos automotores. Contribuí para a melhoria das plataformas de acompanhamento das declarações de pagamento e de controlo dos dados fiscais dos produtores agrícolas. As minhas responsabilidades incluíam o desenvolvimento <strong>PL/SQL, a integração de dados</strong> utilizando <strong>SAS (DI, Flow, Viya, Guide)</strong>, <strong>SQL</strong> e <strong>Python</strong>, bem como a modelação de dados com PowerDesigner e o controlo de versões com <strong>Git</strong>. Orquestrei pipelines ETL, construí dashboards e relatórios, e apoiei a ingestão de dados em <strong>Data Warehouses, Data Marts</strong>, e bases de dados operacionais. Além disso, facilitei a comunicação entre os proprietários de produtos e as equipas de desenvolvimento, assegurando uma entrega ágil através de práticas Scrum/Kanban.",
        "work_cda": "Apoiei a <strong>migração do sistema ERP e da base de dados para Oracle 12c</strong>, adaptando e desenvolvendo <strong>rotinas PL/SQL</strong> e construindo <strong>interfaces modulares utilizando Java</strong>. Trabalhei em processos de modelação, transformação e ETL de dados, e criei <strong>reports e dashboards</strong> para gestores comerciais e auditores internos. Adicionalmente, desenvolvi modelos de <strong>scoring</strong> para otimização das áreas de negócio e prestei <strong>suporte ao utilizador e resolução de problemas</strong> para garantir a fiabilidade do sistema.",
        "contact_title": "Vamos Conversar?",
        "contact_text": "Juntos podemos descobrir como posso agregar valor ao seu próximo desafio!"
    }
}